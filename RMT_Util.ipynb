{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMT Utilility Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T05:34:18.432124Z",
     "start_time": "2018-08-12T05:34:15.053720Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle, time\n",
    "from copy import deepcopy\n",
    "from shutil import copy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import Constant\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.random_projection import sparse_random_matrix\n",
    "import scipy as sp\n",
    "from scipy.linalg import svd\n",
    "\n",
    "import powerlaw\n",
    "from scipy import optimize\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "print(\"numpy version {}\".format(np.__version__))\n",
    "print(\"scipy version {}\".format(sp.__version__))\n",
    "print(\"tensforflow version {}\".format(tf.__version__))\n",
    "print(\"keras version {}\".format(keras.__version__))\n",
    "print(\"sklearn version {}\".format(sklearn.__version__))\n",
    "print(\"powerlaw version {}\".format(powerlaw.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wigner SemiCircle Plots\n",
    "\n",
    "### <font color='orange'>Not available yet </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marchenko Pastur FIts and Plots\n",
    "\n",
    "$$\\rho(\\lambda)=\\dfrac{Q}{2\\pi\\sigma_{mp}^{2}}\\dfrac{(\\lambda^{+}-\\lambda)(\\lambda^{-}-\\lambda)}{\\lambda}$$\n",
    "\n",
    "\n",
    "$$\\lambda^{\\pm}=\\sigma_{mp}^{2}\\left(1\\pm\\dfrac{1}{\\sqrt Q}\\right)^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:23.901963Z",
     "start_time": "2018-08-04T00:19:23.892051Z"
    }
   },
   "outputs": [],
   "source": [
    "def marchenko_pastur_pdf(x_min, x_max, Q, sigma=1):\n",
    "    y=1/Q\n",
    "    x=np.arange(x_min,x_max,0.001)\n",
    "\n",
    "    b=np.power(sigma*(1 + np.sqrt(1/Q)),2) # Largest eigenvalue\n",
    "    a=np.power(sigma*(1 - np.sqrt(1/Q)),2) # Smallest eigenvalue\n",
    "    return x, (1/(2*np.pi*sigma*sigma*x*y))*np.sqrt((b-x)*(x-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T04:51:08.364533Z",
     "start_time": "2018-04-11T04:51:08.350446Z"
    }
   },
   "source": [
    "#### Get sigma from $\\lambda_{max}$ for rectangular matrix\n",
    "\n",
    "\n",
    "$$\\sigma^{2}=\\lambda_{max}\\left(1+\\dfrac{1}{\\sqrt{Q}}\\right)^{-2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T04:52:01.713637Z",
     "start_time": "2018-08-11T04:52:01.700018Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_sigma(Q, evs):\n",
    "    lmax = np.max(evs)\n",
    "    inv_sqQ = 1.0/np.sqrt(Q)\n",
    "    sigma_2 = lmax/np.square(1+inv_sqQ)\n",
    "    sigma = np.sqrt(sigma_2)\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T05:09:05.729969Z",
     "start_time": "2018-08-11T05:09:05.710280Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_lambda_plus(Q, sigma):\n",
    "    return np.power(sigma*(1 + np.sqrt(1/Q)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T05:09:05.782276Z",
     "start_time": "2018-08-11T05:09:05.779201Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_lambda_minus(Q, sigma):\n",
    "    return np.power(sigma*(1 - np.sqrt(1/Q)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:23.917787Z",
     "start_time": "2018-08-04T00:19:23.911921Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Q(W):\n",
    "    if W.shape[1] > W.shape[0]:\n",
    "        M, N = W.shape\n",
    "    else:\n",
    "        N, M = W.shape\n",
    "    Q=N/M\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:23.924319Z",
     "start_time": "2018-08-04T00:19:23.919784Z"
    }
   },
   "outputs": [],
   "source": [
    "def hard_rank(W, sv):\n",
    "    \"\"\"hard rank, using tolerance from numerical recipes, not default scipy tolerance\"\"\"\n",
    "    tol = np.max(sv)*np.finfo(np.float32).eps/(2.0*np.sqrt(np.sum(W.shape)+1))\n",
    "    return np.linalg.matrix_rank(W, tol = tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:23.932018Z",
     "start_time": "2018-08-04T00:19:23.926427Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_eigenvalues(model, weightfile, layer=7):\n",
    "    \"Read the keras weightfile, get weights for the layer, and compute the eigenvalues(-1)\"\n",
    "    W = load_keras_matrix(model, weightfile, layer)\n",
    "    u, sv, vh = svd(W)\n",
    "    eigenvalues = sv*sv\n",
    "    return eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:23.959595Z",
     "start_time": "2018-08-04T00:19:23.934485Z"
    }
   },
   "outputs": [],
   "source": [
    "# uss FAST SVD method: notice we miss 1 eigenvalue here...using \n",
    "def get_shuffled_eigenvalues(W, layer=7, num=100):\n",
    "    \"get eigenvalues for this model, but shuffled, num times\"\n",
    "    \n",
    "    print(\"get_shuffled_eigenvalues\")\n",
    "    N, M = W.shape[0], W.shape[1]       \n",
    "\n",
    "    if (N<M):\n",
    "        N, M = W.shape[1], W.shape[0] \n",
    "   \n",
    "    eigenvalues = []\n",
    "    for idx in tqdm(range(num)):\n",
    "        W_shuf = W.flatten()\n",
    "        np.random.shuffle(W_shuf)\n",
    "        W_shuf = W_shuf.reshape([N,M])\n",
    "\n",
    "        u, sv, vh = svd(W_shuf)\n",
    "\n",
    "        eigenvalues.extend(sv*sv)\n",
    "        \n",
    "    evals = (np.array(eigenvalues).flatten())\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Marchenko Pastur to ESD\n",
    "\n",
    "#### set sigma, or compute sigma from Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.003295Z",
     "start_time": "2018-08-04T00:19:23.961539Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ESD_and_fit(eigenvalues=None, model=None,  weightfile=None, \n",
    "                     layer=2,  Q=1.0, num_spikes=0, sigma=None, \n",
    "                     alpha=0.25, color='blue', skip=False, verbose=True):\n",
    "    \"\"\"Plot histogram of eigenvalues, for Q, and fit Marchenk Pastur.  \n",
    "    If no sigma, calculates from maximum eigenvalue (minus spikes)\n",
    "    Can read keras weights from model if specified\"\"\"\n",
    "    if eigenvalues is None:\n",
    "        eigenvalues = get_eigenvalues(model, weightfile, layer)\n",
    "   \n",
    "    plt.hist(eigenvalues, bins=100, alpha=alpha, color=color, density=True);\n",
    "\n",
    "    if skip:\n",
    "        return\n",
    "    if not (num_spikes):\n",
    "        num_spikes = 0\n",
    "        \n",
    "    # sort, descending order, minus a few max eigenvalues\n",
    "    evals = np.sort(eigenvalues)[::-1][num_spikes:]\n",
    "\n",
    "    if (sigma is None):\n",
    "        sigma=calc_sigma(Q,evals)\n",
    "        \n",
    "    percent_mass = 100.0*(num_spikes)/len(evals)\n",
    "\n",
    "    ev = np.array(evals)\n",
    "    x_min, x_max =  0, np.max(evals)\n",
    "\n",
    "    x, mp = marchenko_pastur_pdf(x_min, x_max, Q, sigma)\n",
    "    if verbose:\n",
    "        print(\"% spikes outside bulk {0:.2f}\".format(percent_mass))\n",
    "        print(\"% sigma {0:.4f}\".format(sigma))\n",
    "\n",
    "    plt.plot(x,mp, linewidth=1, color = 'r')\n",
    "    plt.title(\" W{} ESD, MP Sigma={}\".format(layer,sigma));\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scree Plots:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.011415Z",
     "start_time": "2018-08-04T00:19:24.005242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eigenvalues for correlation weight matrices, for last 2 layers\n",
    "# for Scree plots\n",
    "# check normalization...maybe replace with svd approach above\n",
    "def matrix_eigenvalues(model, layer=2):    \n",
    "    W = model.layers[layer].get_weights()[0]\n",
    "    W = W / np.linalg.norm(W)\n",
    "    WW = np.dot(W.transpose(),W)#/float(N7)\n",
    "    evs, _ = np.linalg.eig(WW)    \n",
    "    return evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.019078Z",
     "start_time": "2018-08-04T00:19:24.013357Z"
    }
   },
   "outputs": [],
   "source": [
    "def scree_plot(model, weightfile, layer=2, color='blue'):    \n",
    "    model.load_weights(weightfile)\n",
    "    evs = matrix_eigenvalues(model, layer)\n",
    "    eigvals = np.flip(np.sort(evs), axis=0)\n",
    "    sing_vals = np.arange(len(eigvals)) + 1\n",
    "    plt.plot(sing_vals, eigvals, color, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft / Stable Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.024098Z",
     "start_time": "2018-08-04T00:19:24.020937Z"
    }
   },
   "outputs": [],
   "source": [
    "def stable_rank(evals):\n",
    "    return np.sum(evals)/np.max(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.029166Z",
     "start_time": "2018-08-04T00:19:24.025972Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer_soft_rank(model, layer):\n",
    "    W = model.layers[layer].get_weights()[0]\n",
    "    return matrix_soft_rank(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.034025Z",
     "start_time": "2018-08-04T00:19:24.030851Z"
    }
   },
   "outputs": [],
   "source": [
    "def keras_layer_soft_rank(model, layer):\n",
    "    W = keras_matrix(model, layer)\n",
    "    return matrix_soft_rank(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.040335Z",
     "start_time": "2018-08-04T00:19:24.035881Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_soft_rank(W):\n",
    "    W=W/np.trace(W)\n",
    "    u, sv, vh = svd(W)\n",
    "    return stable_rank(sv*sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.051081Z",
     "start_time": "2018-08-04T00:19:24.042121Z"
    }
   },
   "outputs": [],
   "source": [
    "def mp_soft_rank(evals, num_spikes):\n",
    "    evals = np.array(evals)\n",
    "    lambda_max = np.max(evals)\n",
    "    if num_spikes> 0:\n",
    "        evals = np.sort(evals)[::-1][num_spikes:]\n",
    "        lambda_plus = np.max(evals)\n",
    "    else:\n",
    "        lambda_plus = lambda_max\n",
    "        \n",
    "    return lambda_plus/lambda_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.051081Z",
     "start_time": "2018-08-04T00:19:24.042121Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_mp_soft_rank(evals, Q, sigma):\n",
    "    \n",
    "    lambda_plus = calc_lambda_plus(Q,sigma)\n",
    "    lambda_max = np.max(evals)\n",
    "  \n",
    "    return lambda_plus/lambda_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T20:06:54.614799Z",
     "start_time": "2018-05-22T20:06:54.609018Z"
    }
   },
   "source": [
    "### Eigenvector Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.056370Z",
     "start_time": "2018-08-04T00:19:24.052877Z"
    }
   },
   "outputs": [],
   "source": [
    "def keras_matrix(model, modelfile, layer):\n",
    "    model.load_weights(modelfile)\n",
    "    W = model.layers[layer].get_weights()[0]\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.062418Z",
     "start_time": "2018-08-04T00:19:24.058537Z"
    }
   },
   "outputs": [],
   "source": [
    "def pytorch_matrix(model, modelfile, layer):\n",
    "   # model.load_weights(modelfile)\n",
    "   # W = model.layers[layer].get_weights()[0]\n",
    "   # return W\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.073422Z",
     "start_time": "2018-08-04T00:19:24.064213Z"
    }
   },
   "outputs": [],
   "source": [
    "def eigenspectrum(W, norm=True):\n",
    "    N, M = W.shape\n",
    "    if N < M:\n",
    "        X = np.dot(W,W.transpose())\n",
    "        \n",
    "    else:\n",
    "        X = np.dot(W.transpose(),W)\n",
    "       \n",
    "    # assumes matrix is full rank\n",
    "    if norm:\n",
    "        #X = X/np.trace(X)\n",
    "        X = X/N\n",
    "        \n",
    "    return np.linalg.eig(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.086042Z",
     "start_time": "2018-08-04T00:19:24.075771Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace with full svd\n",
    "def singular_spectrum(W, norm=False): \n",
    "    if norm:\n",
    "        W = W/np.trace(W)\n",
    "    M = np.min(W.shape)\n",
    "        \n",
    "    svd = TruncatedSVD(n_components=M-1, n_iter=7, random_state=10)\n",
    "    svd.fit(W) \n",
    "    svals = svd.singular_values_\n",
    "    svecs = svd.components_\n",
    "    return svals, svecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:  fix ensemble runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.100443Z",
     "start_time": "2018-08-04T00:19:24.088578Z"
    }
   },
   "outputs": [],
   "source": [
    "def keras_ensemble_spectrum(model, ensemble_weightfile, layer, num_runs):\n",
    "    \"\"\"compute list of arrays of eigenvals and eigenves for an ensemle run\"\"\"\n",
    "    \n",
    "    eigenvalues, eigenvectors = [], []\n",
    "    for i in tqdm(range(1,num_runs+1)):\n",
    "        filename = ensemble_weightfile.format(i)\n",
    "        W = keras_matrix(model, filename, layer)\n",
    "        evs, evecs = eigenspectrum(W)\n",
    "        \n",
    "        eigenvalues.append(evs)\n",
    "        eigenvectors.append(evecs)\n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.113441Z",
     "start_time": "2018-08-04T00:19:24.102343Z"
    }
   },
   "outputs": [],
   "source": [
    "def keras_singular_spectrum(model, ensemble_weightfile, layer, num_runs):\n",
    "    \"\"\"compute list of arrays of singular vals and vectors for an ensemle run\"\"\"\n",
    "    \n",
    "    svalues, svectors = [], []\n",
    "    for i in tqdm(range(1,num_runs+1)):\n",
    "        filename = ensemble_weightfile.format(i)\n",
    "        W = keras_matrix(model, filename, layer)\n",
    "        svs, svecs = singular_spectrum(W)\n",
    "        \n",
    "        svalues.append(svs)\n",
    "        svectors.append(svecs)\n",
    "    return svalues, svectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.119997Z",
     "start_time": "2018-08-04T00:19:24.115978Z"
    }
   },
   "outputs": [],
   "source": [
    "def localization_ratio(vec):\n",
    "    return np.linalg.norm(vec, ord=1) / np.linalg.norm(vec, ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.125565Z",
     "start_time": "2018-08-04T00:19:24.121735Z"
    }
   },
   "outputs": [],
   "source": [
    "def participation_ratio(vec):\n",
    "    return np.linalg.norm(vec, ord=2) / np.linalg.norm(vec, ord=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.131260Z",
     "start_time": "2018-08-04T00:19:24.127199Z"
    }
   },
   "outputs": [],
   "source": [
    "def vector_entropy(u):\n",
    "    \"\"\"Vector entropy, as in the  Porter-Thomas distribution\n",
    "    \n",
    "    see:  https://arxiv.org/pdf/cond-mat/9810255.pdf\n",
    "    \"\"\"\n",
    "    u2 = np.linalg.norm(u)/2\n",
    "    entropy = np.sum(np.exp(-u2)/np.sqrt(2.0*np.pi))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T21:34:59.124609Z",
     "start_time": "2018-05-25T21:34:59.120514Z"
    }
   },
   "source": [
    "### TODO:  Add perEpoch Methods\n",
    "\n",
    "- entropies\n",
    "- ranks\n",
    "- recompute test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.140345Z",
     "start_time": "2018-08-04T00:19:24.133882Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy_per_epoch(model, per_epoch_weightfile, num_epochs, layer):\n",
    "    \"\"\"Computer layer entropy per epoch for a keras layer\"\"\"\n",
    "    entropies = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.load_weights(per_epoch_weightfile.format(epoch))  \n",
    "        entropies.append(layer_entropy(model, layer))\n",
    "\n",
    "    return np.array(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.148909Z",
     "start_time": "2018-08-04T00:19:24.142281Z"
    }
   },
   "outputs": [],
   "source": [
    "def stable_rank_per_epoch(model, per_epoch_weightfile, num_epochs, layer):\n",
    "    \"\"\"Computer layer entropy per epoch for a keras layer\"\"\"\n",
    "    ranks = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.load_weights(per_epoch_weightfile.format(epoch))  \n",
    "        entropies.append(layer_stable_rank(model, layer))\n",
    "\n",
    "    return np.array(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.161797Z",
     "start_time": "2018-08-04T00:19:24.151414Z"
    }
   },
   "outputs": [],
   "source": [
    "def discrete_entropy(vec, num_bins=100):\n",
    "    vec = vec - np.mean(vec)\n",
    "    h = np.histogram(vec, density=True, bins=num_bins)[0];\n",
    "    p = np.array(h)+0.0000000001\n",
    "    \n",
    "    p = p / np.sqrt(2*np.pi)\n",
    "    p = p / np.sum(p)\n",
    "\n",
    "    #p = p/(2*np.pi)\n",
    "    entropy = -np.sum(p*np.log(p))\n",
    "    entropy = entropy#/(2*np.pi)#/float(num_bins)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.171041Z",
     "start_time": "2018-08-04T00:19:24.163753Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_discrete_entropy(len_vec,num_bins=100, sample_size = 100000):\n",
    "    \"\"\"compute maximum possible entropy for this vector length and bin sizes\"\"\"\n",
    "    entropies = []\n",
    "    for i in tqdm(range(sample_size)):\n",
    "        test_vec = np.random.normal(0,1,len_vec)\n",
    "        s = discrete_entropy(test_vec, num_bins=num_bins)\n",
    "        entropies.append(s)\n",
    "\n",
    "    return np.max(entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.175368Z",
     "start_time": "2018-08-04T00:19:24.172831Z"
    }
   },
   "outputs": [],
   "source": [
    "def spike_min(Q):\n",
    "    \"\"\"minimum perturbation to W to see a spike\"\"\"\n",
    "    return 1/np.sqrt(np.sqrt(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.180434Z",
     "start_time": "2018-08-04T00:19:24.177110Z"
    }
   },
   "outputs": [],
   "source": [
    "def spike_lmax(S,Q):\n",
    "    \"\"\"Maximum spike given a perturbation\"\"\"\n",
    "    S2 = S*S\n",
    "    return ((1.0/Q)+S2)*(1+(1.0/S2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit PowerLaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.191760Z",
     "start_time": "2018-08-04T00:19:24.182535Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.198789Z",
     "start_time": "2018-08-04T00:19:24.193422Z"
    }
   },
   "outputs": [],
   "source": [
    "def mu4alpha(alpha):\n",
    "    if (alpha >= 2.0 and alpha <= 3.0):\n",
    "        mu = 2.0\n",
    "    elif (alpha < 2.0):\n",
    "        mu = 2.0*(alpha - 1.0)\n",
    "    elif (alpha > 3.0):\n",
    "        mu = alpha - 1.0\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:19:24.222560Z",
     "start_time": "2018-08-04T00:19:24.200504Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_dist(fit):\n",
    "    distName = 'power_law'\n",
    "    dist = \"PL\"\n",
    "\n",
    "    R, p = fit.distribution_compare('truncated_power_law', 'power_law', normalized_ratio=True)\n",
    "    if R>0 and p <= 0.05:\n",
    "        distName = 'truncated_power_law'\n",
    "        dist = 'TPL'\n",
    "        \n",
    "    R, p = fit.distribution_compare(distName, 'exponential', normalized_ratio=True)\n",
    "    if R<0 and p <= 0.05:\n",
    "        dist = 'EXP'\n",
    "        return dist\n",
    "\n",
    "    R, p = fit.distribution_compare(distName, 'stretched_exponential', normalized_ratio=True)\n",
    "    if R<0 and p <= 0.05:\n",
    "        dist = 'S_EXP'\n",
    "        return dist\n",
    "        \n",
    "    R, p = fit.distribution_compare(distName, 'lognormal', normalized_ratio=True)\n",
    "    if R<0 and p <= 0.05:\n",
    "        dist = 'LOG_N'\n",
    "        return dist\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T05:17:50.236828Z",
     "start_time": "2018-08-19T05:17:50.233302Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_powerlaw(evals, verbose=True):\n",
    "    fit = powerlaw.Fit(evals, xmax=np.max(evals))\n",
    "    return [fit.alpha, fit.D, best_dist(fit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T05:36:39.965936Z",
     "start_time": "2018-08-19T05:36:39.951343Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_plot_powerlaw(evals, verbose=True):\n",
    "    fit = powerlaw.Fit(evals, xmax=np.max(evals))\n",
    "    \n",
    "    alpha, D, best_pl = fit.alpha, fit.D, best_dist(fit)\n",
    "    \n",
    "    print(\"alpha {:3g}, D {:3g}, best_pl  {}\".format(alpha, D, best_pl))\n",
    "    \n",
    "    fig2 = fit.plot_pdf(color='b', linewidth=2)\n",
    "    fit.power_law.plot_pdf(color='b', linestyle='--', ax=fig2)\n",
    "    fit.plot_ccdf(color='r', linewidth=2, ax=fig2)\n",
    "    fit.power_law.plot_ccdf(color='r', linestyle='--', ax=fig2)\n",
    "    plt.show()           \n",
    "            \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T04:16:02.812823Z",
     "start_time": "2018-08-04T04:16:02.785750Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Try all reshapings\n",
    "def reshape_tensor(W):\n",
    "    \"reshape tensor into a maximum rectangle.  Usually the max dimension (N) is the last, so just preserve it\"\n",
    "    dims = W.shape\n",
    "    N = np.max(dims)\n",
    "    print(dims)\n",
    "\n",
    "    M = 1\n",
    "    for d in dims:\n",
    "        M = M*d\n",
    "    M = int(M / N)\n",
    "    \n",
    "    if dims[-1]==N:\n",
    "        Ws = np.reshape(W,(M,N))\n",
    "    else:\n",
    "        Ws = np.reshape(W,(N,M))\n",
    "        \n",
    "    print(Ws.shape)\n",
    "    return Ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto fit MP \n",
    "\n",
    "#### Using Kernel Density Estimator\n",
    "\n",
    "### TODO: float num_spikes, or grid search as int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T02:04:00.000151Z",
     "start_time": "2018-08-10T02:03:59.730894Z"
    }
   },
   "outputs": [],
   "source": [
    "def marchenko_pastur_fun(x, Q, sigma=1):\n",
    "    y=1/Q\n",
    "    \n",
    "    b=np.power(sigma*(1 + np.sqrt(1/Q)),2) # Largest eigenvalue\n",
    "    a=np.power(sigma*(1 - np.sqrt(1/Q)),2) # Smallest eigenvalue\n",
    "    return x, (1/(2*np.pi*sigma*sigma*x*y))*np.sqrt((b-x)*(x-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T03:43:59.943978Z",
     "start_time": "2018-08-11T03:43:59.859092Z"
    }
   },
   "outputs": [],
   "source": [
    "def resid_mp(p, evals, Q, num_spikes=0, bw=0.1, debug=False):  \n",
    "    \"residual that floats sigma but NOT Q or num_spikes YET, 10% cutoff each edge\"\n",
    "    sigma = p\n",
    "\n",
    "    # kernel density estimator\n",
    "    kde = KernelDensity(kernel='linear', bandwidth=bw).fit(evals.reshape(-1, 1))\n",
    "    xde =  np.linspace(0, np.max(evals)+0.5, 1000)\n",
    "    X_plot =xde[:, np.newaxis]\n",
    "    log_dens = kde.score_samples(X_plot)\n",
    "    yde = np.exp(log_dens)   \n",
    "    \n",
    "    # MP fit for this sigma\n",
    "    xmp, ymp = marchenko_pastur_fun(xde, Q=Q, sigma=sigma)\n",
    "    \n",
    "    # form residual, remove nan's \n",
    "    resid = ymp-yde\n",
    "    resid = np.nan_to_num(resid)\n",
    "    \n",
    "    if debug:\n",
    "        plt.plot(xde,yde)\n",
    "        plt.plot(xmp,ymp)\n",
    "        plt.show()\n",
    "        print(\"sigma {}  mean residual {}\".format(sigma,np.mean(resid)))\n",
    "\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T03:55:00.200174Z",
     "start_time": "2018-08-11T03:55:00.187135Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_mp(evals, Q):\n",
    "    \"simple fit of evals, only floats sigma right now\"\n",
    "    sigma0=1.0\n",
    "    [sigma1],cov,infodict,mesg,ierr   = optimize.leastsq(resid_mp, [sigma0], args=(evals, Q), full_output=True)\n",
    "    return sigma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
